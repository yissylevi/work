---
title: "Machine Learning Assignment"
author: "Levi Brackman"
date: "February 22, 2016"
output: html_document
---
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).
```{r}
#Load the training and testing dataset. Take a look and see the dimensions
```{r}
training<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), na.strings=c("","#DIV/0!","NA"))
#View(training)
testing<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), na.strings=c("","#DIV/0!","NA"))
dim(training); dim(testing)
```
Remove the colunms that are not relevant for predicting such as ID
```{r, echo=FALSE}
require(dplyr)
#detach("package:dplyr", character.only = TRUE)
#library("dplyr", character.only = TRUE)
training<- select(training, -c(user_name,	raw_timestamp_part_1,	raw_timestamp_part_2,	cvtd_timestamp,	new_window,	num_window))
testing<- select(testing, -c(user_name,	raw_timestamp_part_1,	raw_timestamp_part_2,	cvtd_timestamp,	new_window,	num_window))
```
Dealing with missing data missing data. It truns out that there is so much missing data that we are unable to do imputation using k-nearest neighbours. So instead we remove the veriables with the missing data from the analysis and build models using the veriables (co-veriates) that have full data.
```{r, echo=FALSE}
library(Amelia)
missmap(training, main = "Missingness Map Test")
#install.packages("VIM")
#require(VIM)
#install.packages("DMwR")
#require(DMwR)
#training<-knnImputation(training)
#unable to impute missing data so will remove missing data 
missing<-colnames(training)[colSums(is.na(training)) > 0]
#dput(as.character(missing))
require(caret)
training<-select(training, -c(kurtosis_roll_belt, kurtosis_picth_belt, kurtosis_yaw_belt,
+  skewness_roll_belt, skewness_roll_belt.1, skewness_yaw_belt,
+  max_roll_belt, max_picth_belt, max_yaw_belt, min_roll_belt,
+  min_pitch_belt, min_yaw_belt, amplitude_roll_belt, amplitude_pitch_belt,
+  amplitude_yaw_belt, var_total_accel_belt, avg_roll_belt,
+  stddev_roll_belt, var_roll_belt, avg_pitch_belt, stddev_pitch_belt,
+  var_pitch_belt, avg_yaw_belt, stddev_yaw_belt, var_yaw_belt,
+  var_accel_arm, avg_roll_arm, stddev_roll_arm, var_roll_arm,
+  avg_pitch_arm, stddev_pitch_arm, var_pitch_arm, avg_yaw_arm,
+  stddev_yaw_arm, var_yaw_arm, kurtosis_roll_arm, kurtosis_picth_arm,
+  kurtosis_yaw_arm, skewness_roll_arm, skewness_pitch_arm,
+  skewness_yaw_arm, max_roll_arm, max_picth_arm, max_yaw_arm,
+  min_roll_arm, min_pitch_arm, min_yaw_arm, amplitude_roll_arm,
+  amplitude_pitch_arm, amplitude_yaw_arm, kurtosis_roll_dumbbell,
+  kurtosis_picth_dumbbell, kurtosis_yaw_dumbbell, skewness_roll_dumbbell,
+  skewness_pitch_dumbbell, skewness_yaw_dumbbell, max_roll_dumbbell,
+  max_picth_dumbbell, max_yaw_dumbbell, min_roll_dumbbell,
+  min_pitch_dumbbell, min_yaw_dumbbell, amplitude_roll_dumbbell,
+  amplitude_pitch_dumbbell, amplitude_yaw_dumbbell, var_accel_dumbbell,
+  avg_roll_dumbbell, stddev_roll_dumbbell, var_roll_dumbbell,
+  avg_pitch_dumbbell, stddev_pitch_dumbbell, var_pitch_dumbbell,
+  avg_yaw_dumbbell, stddev_yaw_dumbbell, var_yaw_dumbbell,
+  kurtosis_roll_forearm, kurtosis_picth_forearm, kurtosis_yaw_forearm,
+  skewness_roll_forearm, skewness_pitch_forearm, skewness_yaw_forearm,
+  max_roll_forearm, max_picth_forearm, max_yaw_forearm, min_roll_forearm,
+  min_pitch_forearm, min_yaw_forearm, amplitude_roll_forearm,
+  amplitude_pitch_forearm, amplitude_yaw_forearm, var_accel_forearm,
+  avg_roll_forearm, stddev_roll_forearm, var_roll_forearm,
+  avg_pitch_forearm, stddev_pitch_forearm, var_pitch_forearm,
+  avg_yaw_forearm, stddev_yaw_forearm, var_yaw_forearm))

testing<-select(testing, -c(kurtosis_roll_belt, kurtosis_picth_belt, kurtosis_yaw_belt,
+  skewness_roll_belt, skewness_roll_belt.1, skewness_yaw_belt,
+  max_roll_belt, max_picth_belt, max_yaw_belt, min_roll_belt,
+  min_pitch_belt, min_yaw_belt, amplitude_roll_belt, amplitude_pitch_belt,
+  amplitude_yaw_belt, var_total_accel_belt, avg_roll_belt,
+  stddev_roll_belt, var_roll_belt, avg_pitch_belt, stddev_pitch_belt,
+  var_pitch_belt, avg_yaw_belt, stddev_yaw_belt, var_yaw_belt,
+  var_accel_arm, avg_roll_arm, stddev_roll_arm, var_roll_arm,
+  avg_pitch_arm, stddev_pitch_arm, var_pitch_arm, avg_yaw_arm,
+  stddev_yaw_arm, var_yaw_arm, kurtosis_roll_arm, kurtosis_picth_arm,
+  kurtosis_yaw_arm, skewness_roll_arm, skewness_pitch_arm,
+  skewness_yaw_arm, max_roll_arm, max_picth_arm, max_yaw_arm,
+  min_roll_arm, min_pitch_arm, min_yaw_arm, amplitude_roll_arm,
+  amplitude_pitch_arm, amplitude_yaw_arm, kurtosis_roll_dumbbell,
+  kurtosis_picth_dumbbell, kurtosis_yaw_dumbbell, skewness_roll_dumbbell,
+  skewness_pitch_dumbbell, skewness_yaw_dumbbell, max_roll_dumbbell,
+  max_picth_dumbbell, max_yaw_dumbbell, min_roll_dumbbell,
+  min_pitch_dumbbell, min_yaw_dumbbell, amplitude_roll_dumbbell,
+  amplitude_pitch_dumbbell, amplitude_yaw_dumbbell, var_accel_dumbbell,
+  avg_roll_dumbbell, stddev_roll_dumbbell, var_roll_dumbbell,
+  avg_pitch_dumbbell, stddev_pitch_dumbbell, var_pitch_dumbbell,
+  avg_yaw_dumbbell, stddev_yaw_dumbbell, var_yaw_dumbbell,
+  kurtosis_roll_forearm, kurtosis_picth_forearm, kurtosis_yaw_forearm,
+  skewness_roll_forearm, skewness_pitch_forearm, skewness_yaw_forearm,
+  max_roll_forearm, max_picth_forearm, max_yaw_forearm, min_roll_forearm,
+  min_pitch_forearm, min_yaw_forearm, amplitude_roll_forearm,
+  amplitude_pitch_forearm, amplitude_yaw_forearm, var_accel_forearm,
+  avg_roll_forearm, stddev_roll_forearm, var_roll_forearm,
+  avg_pitch_forearm, stddev_pitch_forearm, var_pitch_forearm,
+  avg_yaw_forearm, stddev_yaw_forearm, var_yaw_forearm))
#remove the number colunm
training<-select(training, -1)
testing<-select(testing, -1)
```
Creat a training and validation set
```{r, echo=FALSE, cache=TRUE}
set.seed(4234242)
inTrain <- createDataPartition(y=training$classe, p= 0.70, list=FALSE)
train <- training[inTrain,]
validation <- training[-inTrain,]
dim(train);dim(validation)
```
Build three different models. Starting with a model using Random Forest. We can see that when tested on the validation set we get a 100% accuracy level.
```{r, echo=FALSE, cache=TRUE}
set.seed(4234242)
modRF <- train(classe ~.,method="rf", data=training, importance = TRUE, trControl = trainControl(method = "cv", number = 3))
#save(modRF,file="modRF.RData")
#load("modRF.RData")
modRF$finalModel
insampleRF<-print(modRF)
insampleRF<-insampleRF[2,2]
Imp <- varImp(modRF)
Imp$importance[1:10,]
pred1 <- predict(modRF, validation)
cm1 <- confusionMatrix(pred1, validation$classe)
cm1
```
Create a Decision Trees Model. When tested on the validation set we only get a 49% accuracy levle. This is significantly lower than the Random Forest model.
```{r, cache=TRUE, echo=FALSE}
modTrees <- train(classe ~.,method="rpart", data=training)
modTrees$finalModel
insampleTrees<-print(modTrees)
insampleTrees<-insampleTrees[1,2]
Imp <- varImp(modTrees)
Imp$importance[1:10,]
pred2 <- predict(modTrees, validation)
cm2 <- confusionMatrix(pred2, validation$classe)
cm2
```
Creat a Boosted Trees Model. Boosted Trees are significantly better than a regular decision tree model with 97% accuracy rate.
```{r, cache=TRUE, echo=FALSE}
modGBM <- train(classe ~.,method="gbm",data=training)
modGBM$finalModel
insampleGBM<-print(modGBM)
insampleGBM<-insampleGBM[9,3]
Imp <- varImp(modTrees)
Imp$importance[1:10,]
pred3 <- predict(modGBM, validation)
cm3 <- confusionMatrix(pred3, validation$classe)
cm3
```
Create a Linear Discriminant Analysis (LDA) Model. LDA is worse than the boosted model giving us only a 71% accuracy rate on the validation set. 
```{r, cache=TRUE, echo=FALSE}
modLDA <- train(classe ~.,method="lda",data=training)
modLDA$finalModel
insampleLDA<-print(modLDA)
insampleLDA<-insampleLDA[1,1]
pred4 <- predict(modLDA, validation)
cm4 <- confusionMatrix(pred4, validation$classe)
cm4
```
Here we create a table of accuracy measures and as this shows clearly Random Forest gives us the best accuracy rate.
```{r, echo=FALSE}
accuraciesinsam<-data.frame(as.numeric(insampleRF), as.numeric(insampleTrees), as.numeric(insampleGBM), as.numeric(insampleLDA))
colnames(accuraciesinsam) <- c("Random Forest", "Decision Trees", "Boosted Trees", "Linear Discriminant Analysis")

accuracies<-data.frame(cm1$overall['Accuracy'], cm2$overall['Accuracy'], cm3$overall['Accuracy'], cm4$overall['Accuracy'])
colnames(accuracies) <- c("Random Forest", "Decision Trees", "Boosted Trees", "Linear Discriminant Analysis")
```
Accuracy rate on training set
```{r}
accuraciesinsam
```
Accuracy rate on validation set
```{r}
accuracies
```
Here we craete an in and out of sample error rate table for all four of our models. As one can see the in-sample error rate is higher for Random Forest, Linear Discriminant Analysis and Boosted Trees and lower for Decision Trees.
```{r, echo=FALSE}
InSample <- 1-accuraciesinsam
rownames(InSample) <- "In Sample Error"
InSample

OutofSample <- 1-accuracies
rownames(OutofSample) <- "Out of Sample Error"
OutofSample
```
Predict the classe variable of the testing data
```{r}
ClasseTesting <- predict(modRF, testing)
ClasseTesting
```
## Appendix
```{r code=readLines(knitr::purl('/Users/levibrackman/courses/08_PracticalMachineLearning/assignment.Rmd', documentation = 0)), eval = FALSE}

```
